# -*- coding: utf-8 -*-
"""binary_classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1wCqCqB8Rp6me0CV53qvTOECcm5nV3F4o
"""

from google.colab import drive
drive.mount('/content/drive')

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense

train_data='/content/drive/MyDrive/k s shubham/cnn'
validation_data='/content/drive/MyDrive/k s shubham/cnn'

train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(train_data, target_size=(150, 150), batch_size=4, class_mode='categorical')
validation_generator = test_datagen.flow_from_directory(validation_data, target_size=(150, 150), batch_size=4, class_mode='categorical')

num_classes=2

model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150,150,3)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(num_classes, activation='sigmoid'))

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

history = model.fit(train_generator, epochs=10, validation_data=validation_generator)

# Path to save the model in your Google Drive
model_save_path = '/content/drive/MyDrive/my_models/model.h5'

# Path to save the model in your Google Drive
model.save('/content/drive/MyDrive/my_models/model.h5')

from tensorflow.keras.models import load_model

# Path to the saved model in Drive
model_path = '/content/drive/MyDrive/my_models/model.h5'

# Load the model
model = load_model(model_path)
print("Model loaded successfully!")

model = tf.keras.models.load_model('/content/drive/MyDrive/my_models/model.h5')  # Load the SavedModel

import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import load_img, img_to_array
import matplotlib.pyplot as plt

# Step 1: Load the Trained Model
model_path = '/content/drive/MyDrive/my_models/model.h5'  # Path to your saved model
model = load_model(model_path)

# Step 2: Define Helper Function for Predictions
def predict_image(image_path, model, class_names, image_size=(150, 150)):
    # Load the image and preprocess it
    img = load_img(image_path, target_size=image_size)  # Resize the image
    img_array = img_to_array(img) / 255.0  # Normalize pixel values to [0, 1]
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension

    # Make predictions
    prediction = model.predict(img_array)
    predicted_class = class_names[int(prediction[0][0] > 0.5)]  # 0 = Cat, 1 = Dog
    confidence = prediction[0][0] if prediction[0][0] > 0.5 else 1 - prediction[0][0]

    # Display the result
    plt.imshow(img)
    plt.title(f"Prediction: {predicted_class} \nConfidence: {confidence:.2f}")
    plt.axis('off')
    plt.show()

# Step 3: Class Names
class_names = ["shubham", "manish"]  # 0 = Cat, 1 = Dog

# Step 4: Predict for a Test Image
image_path = '/content/drive/MyDrive/test_images/IMG_8442.JPG'  # Path to the test image
predict_image(image_path, model, class_names)

pip install gTTS

pip install tensorflow pillow pyttsx3

!sudo apt-get update
!sudo apt-get install espeak-ng

import tensorflow as tf
from tensorflow.keras.preprocessing import image
import pyttsx3
import numpy as np
from PIL import Image
from gtts import gTTS
import os

# Load a pre-trained model (e.g., MobileNetV2 for cat/dog classification)
model = tf.keras.applications.MobileNetV2(weights='imagenet')

# Initialize pyttsx3 TTS engine
engine = pyttsx3.init()

# Function to prepare and predict the image
def predict_image(img_path):
    # Load the image and resize it to fit the model's input size (224x224 for MobileNetV2)
    img = Image.open(img_path).resize((224, 224))
    img_array = np.array(img)

    # Preprocess the image to match the input format for MobileNetV2
    img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)
    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension

    # Make the prediction
    predictions = model.predict(img_array)

    # Decode predictions into labels (this model uses ImageNet classes)
    decoded_predictions = tf.keras.applications.mobilenet_v2.decode_predictions(predictions, top=1)
    label = decoded_predictions[0][0][1]  # Get the label (top prediction)

    return label

# Function to convert label to speech (using pyttsx3)
def text_to_speech(label):
    engine.say(f"The predicted label is {label}")
    engine.runAndWait()

# Function to convert label to speech (using gTTS)
def text_to_speech_gTTS(label):
    tts = gTTS(text=f"The predicted label is {label}", lang='en')
    tts.save("output.mp3")
    os.system("start output.mp3")  # For Windows
    # For Linux/macOS, use os.system("mpg321 output.mp3")

# Example usage:
img_path = '/content/drive/MyDrive/test_images/IMG_8543.JPG'  # Replace with the path to your image

# Make sure the label is correctly predicted
label = predict_image(img_path)

# Print predicted label
print(f"Predicted Label: {label}")

# Convert label to speech using pyttsx3
text_to_speech(label)

# Alternatively, convert label to speech using gTTS
# text_to_speech_gTTS(label)

